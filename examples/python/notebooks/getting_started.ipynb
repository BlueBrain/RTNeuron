{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  },
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We start by importing the rtneuron Python module. When rtneuron is started with no arguments it launches an IPython shell whose namespace is the namespace of the rtneuron module, so there is no need to import it (this is in a way similar to from rtneuron import *, but not exactly the same)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import rtneuron\n",
      "\n",
      "# The following code is used to reduce the size of the output images from the default one.\n",
      "rtneuron.global_attributes.window_width = 900\n",
      "rtneuron.global_attributes.window_height = 500\n",
      "import os\n",
      "if 'EQ_WINDOW_IATTR_HINT_FULLSCREEN' in os.environ:\n",
      "    del os.environ['EQ_WINDOW_IATTR_HINT_FULLSCREEN']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As a quick start you can use `display_circuit` to show a list of cell sets. This will create an RTNeuron engine object, initialize the rendering context and populate the scene with the given targets"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "blueconfig = \"/gpfs/bbp.cscs.ch/project/proj3/resources/circuits/ReleaseL2_fixed\"\n",
      "rtneuron.display_circuit(blueconfig, 6523)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The function ``rtneuron.snapshot_to_notebook`` is provided to directly embed snapshots into a IPython notebook. This function takes a view as its argument. Another way of getting snapshot is using the ``view.snapshot`` function, which takes as an argument the file path of the output image."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rtneuron.snapshot_to_notebook(rtneuron.engine.views[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rtneuron.display_circuit(blueconfig,\n",
      "                         [6523, # First target of a target list\n",
      "                          ('MiniColumn_0', {'mode': rtneuron.RepresentationMode.SOMA,\n",
      "                                            'color': [1, 0, 0, 1]}) # Second one, with attributes\n",
      "                         ])\n",
      "rtneuron.snapshot_to_notebook(rtneuron.engine.views[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Once a scene is created it is possible to add synapses to it. The following code adds all the afferent synapses of a neuron to the scene."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rtneuron.display_circuit(blueconfig, 6523)\n",
      "# This function doesn't directly accept a dictionary for the attributes, it has to be\n",
      "# an AttributeMap instead.\n",
      "rtneuron.display_synapses(\n",
      "    6523, attributes=rtneuron.AttributeMap({'color': [1, 1, 0, 1], 'radius': 3}))\n",
      "rtneuron.snapshot_to_notebook(rtneuron.engine.views[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A typical use case is to show the synapses shared by two or more cells."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pre = 77403\n",
      "post = 78389\n",
      "rtneuron.display_circuit(blueconfig, [(pre, {'color': [1, 1, 0, 1]}), # presynaptic\n",
      "                                      (post, {'color': [0, 0, 1, 1]})]) # postsynaptic\n",
      "rtneuron.display_shared_synapses(pre, post,\n",
      "                                 attributes=rtneuron.AttributeMap({'color': [1, 0, 0, 1], 'radius': 4}))\n",
      "view = rtneuron.engine.views[0]\n",
      "view.attributes.background = [1, 1, 1, 1]\n",
      "rtneuron.snapshot_to_notebook(view)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "When a simulation is loaded from the command line or the `display_circuit` function is called several global objects become available at the rtneuron module (or the shell is running inside the IPython console launched by `rtneuron`:\n",
      "  - `engine`: The `RTNeuron` instance\n",
      "  - `simulation`: The `brain.Simulation` object with the blue config loaded.\n",
      "  \n",
      "Apart from the helper methods showed so far, a scene can also be populated manually starting from an empty scene. The functions to do so are:\n",
      "  - `Scene.addNeurons`\n",
      "  - `Scene.addAfferentSynapses` and `Scene.addEfferentSynapses`\n",
      "  - `Scene.addModel` and `Scene.addGeometry`\n",
      "  \n",
      "These methods handle to the scene object created. The handle can be used to modify some properties of the scene objects or to remove then from the scene."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import brain\n",
      "import numpy\n",
      "\n",
      "view = rtneuron.display_empty_scene()\n",
      "scene = view.scene\n",
      "\n",
      "blueconfig = \"/gpfs/bbp.cscs.ch/project/proj3/resources/circuits/ReleaseL2_fixed\"\n",
      "# Opening a simulation and assigning the circuit to the scene\n",
      "simulation = brain.Simulation(blueconfig)\n",
      "target = numpy.intersect1d(simulation.gids('mc2_Column'),\n",
      "                           simulation.gids('Layer4'))\n",
      "\n",
      "attributes = rtneuron.AttributeMap()\n",
      "attributes.mode = rtneuron.RepresentationMode.SOMA\n",
      "handler = scene.addNeurons(target, attributes)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# We can add a vertical line through the centroid of the target displayed\n",
      "circuit = scene.circuit\n",
      "positions = circuit.positions(circuit.gids('mc2_Column'))\n",
      "center = positions.mean(axis=0)\n",
      "bottom = [center[0], -500, center[2]]\n",
      "top = [center[0], 2500, center[2]]\n",
      "scene.addGeometry([top, bottom], [[0, 1]], attributes = rtneuron.AttributeMap({'mode': 'lines', 'line_width': 2}))\n",
      "\n",
      "# A helper function can be used to add a hexagonal prism to the scene.\n",
      "rtneuron.add_hexagonal_prism(scene, [center[0], 0, center[2]], 2000, 270)\n",
      "# In order to see the interior we have to enable transparency\n",
      "rtneuron.sceneops.enable_transparency(scene)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "view = rtneuron.engine.views[0]\n",
      "view.attributes.background = [1, 1, 1, 1]\n",
      "view.camera.setView([-1055, 2410, 990], ([-0.5969, -0.7982, -0.080], 76.79247283935547))\n",
      "rtneuron.snapshot_to_notebook(view)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The doxygen documentation of all objects from the `rtneuron` module is available as regular docstrings (these include also the wrapping documentation generated by Boost.Python automatically). If IPython is found tab-completion will work in the shell.\n",
      "\n",
      "Some objects provide an attribute based API exposed by an object property called `attributes`, this object is and instance of `AttributeMap`. In Python this object appears as an object in which attributes of arbitrary names can be added to the instance. The attribute value types are limited to `int`, `str`, `double`, `bool` and lists of those. `AttributeMap's` can be nested but a list attribute cannot contain another attribute map. Some attribute maps can provide documentation about its attributes using the `help()` function. This works for example for the `View` object."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "view.attributes.help()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}
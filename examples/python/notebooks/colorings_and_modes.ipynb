{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The most immediate thing that can be done with the rtneuron module is to display one test circuit. By default, only the somata are displayed, using spheres to represent them, but this can be changed by provinding each target as a tuple of the target key and the attribute dict."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "import rtneuron\n",
      "import os\n",
      "\n",
      "# Presetting the global variables for the default window size\n",
      "rtneuron.global_attributes.window_width = 800\n",
      "rtneuron.global_attributes.window_height = 1100\n",
      "if 'EQ_WINDOW_IATTR_HINT_FULLSCREEN' in os.environ:\n",
      "    del os.environ['EQ_WINDOW_IATTR_HINT_FULLSCREEN']\n",
      "    \n",
      "# By default, morphologies are loaded even in soma only mode to find out the soma radius.\n",
      "# This can be disabled by uncommenting the line below.\n",
      "# rtneuron.default_scene_attributes.load_morphologies = False\n",
      "\n",
      "#blueconfig = \"/gpfs/bbp.cscs.ch/release/l2/2012.07.23/circuit/O1/merged_circuit/CircuitConfig\"\n",
      "blueconfig = \"/gpfs/bbp.cscs.ch/project/proj3/resources/circuits/ReleaseL2_fixed\"\n",
      "rtneuron.display_circuit(blueconfig, ('mc2_Column', {\"mode\": rtneuron.RepresentationMode.SOMA}))\n",
      "view = rtneuron.engine.views[0]\n",
      "view.attributes.background = [1, 1, 1, 1]\n",
      "scene = view.scene\n",
      "simulation = rtneuron.simulation\n",
      "rtneuron.snapshot_to_notebook(view)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Using the handler object that represents all the neurons added to the scene we can, for example, change the color of the neurons. This property is accessed through the *attributes* member of the handler."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "all_neurons = scene.objects[0]\n",
      "all_neurons.attributes.color = [0, 0, 1, 1]\n",
      "all_neurons.update()\n",
      "rtneuron.snapshot_to_notebook(view)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we will obtain the list of cell IDs of each layer. Each layer has a *target* name associated with it. There are *targets* also for other circuit subsets. The targets for layers are queried from the simulation. The ids are used to query subsets of the scene object that represents the whole circuit. Each query returns a handler that can be used to modify the attributes of the subset it represents. The list of ids of each query may overlap. In this case, the properties of the last handler applied prevail.\n",
      "\n",
      "In this case we are going to change the color of each layer."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "layer_ids =[]\n",
      "for i in range(1, 7):\n",
      "    layer_ids.append(simulation.gids('Layer%d' % i))\n",
      "\n",
      "\n",
      "layers = [all_neurons.query(ids) for ids in layer_ids]\n",
      "colors = [[1, 0, 0, 1], [1, 0.5, 0, 1], [1, 1, 0, 1],\n",
      "          [0.3, 1.0, 0, 1], [0, 0.8, 0.8, 1], [0, 0.5, 1, 1]]\n",
      "for layer, color in zip(layers, colors):\n",
      "    layer.attributes.color = color\n",
      "    layer.update()\n",
      "rtneuron.snapshot_to_notebook(view)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It is possible to modify the representation of neurons dynamically, for example to show the full morphology of selected neurons. Data will be loaded on demand as needed."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ids = simulation.gids('mc2_MiniColumn_0')\n",
      "minicolumn = all_neurons.query(ids)\n",
      "minicolumn.attributes.mode = rtneuron.RepresentationMode.WHOLE_NEURON\n",
      "minicolumn.update()\n",
      "rtneuron.snapshot_to_notebook(view)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "After enabling transparency on the scene we can modify the alpha channel of the colors to make the neurons outside our target of interest less visible."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rtneuron.sceneops.enable_transparency(scene)\n",
      "for layer in layers:\n",
      "    c = layer.attributes.color\n",
      "    # layer.attributes.color[3] = 0.2 won't work as expected. Without getting\n",
      "    # into too many details, AttributeMap is special in the sense that attributes.color\n",
      "    # creates a temporary variable, so to change the color you have to reset it.\n",
      "    c[3] = 0.1\n",
      "    layer.attributes.color = c\n",
      "    layer.update()\n",
      "# The layers overlap with minicolumn, so it becomes dirty. Calling update resets\n",
      "# its attributes.\n",
      "minicolumn.update()\n",
      "rtneuron.snapshot_to_notebook(view)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can also display axon and dendrites with different colors or display only the dendrites of specific cells."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "minicolumn.attributes.color = [1, 0, 0, 1]\n",
      "minicolumn.attributes.secondary_color = [0, 0.5, 1, 1]\n",
      "minicolumn.attributes.color_scheme = rtneuron.ColorScheme.BY_BRANCH_TYPE\n",
      "minicolumn.update()\n",
      "rtneuron.snapshot_to_notebook(view)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "minicolumn.attributes.mode = rtneuron.RepresentationMode.NO_AXON\n",
      "minicolumn.update()\n",
      "rtneuron.snapshot_to_notebook(view)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Another option is to color the branches according to the value of some property. The currently supported modes are coloring by distance to soma and by branch width."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import math\n",
      "colormap = rtneuron.ColorMap()\n",
      "# The following colormap is a non linear function that mimics light attenuation based on an absortion\n",
      "# coefficient. The final images are not phisically correct because the attenuation is visualized as\n",
      "# if branches were perpendicular to light rays, but gives a good result.\n",
      "absortion_coeff = 20\n",
      "points = dict()\n",
      "max_width = 80\n",
      "for i in range(50):\n",
      "    width = max_width * i / 49.0\n",
      "    alpha = 1 - math.exp(-width * 1/absortion_coeff)\n",
      "    points[width] = [alpha * 0.5, alpha, 1, alpha]\n",
      "colormap.setPoints(points)\n",
      "\n",
      "minicolumn.attributes.colormaps = rtneuron.AttributeMap()\n",
      "minicolumn.attributes.colormaps.by_width = colormap\n",
      "minicolumn.attributes.color_scheme = rtneuron.ColorScheme.BY_WIDTH\n",
      "minicolumn.update()\n",
      "rtneuron.snapshot_to_notebook(view)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}